{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8NeYLe4t4mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBy_Qo7Yt_kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "0427909a-3efa-4a72-90a4-5e26d4dd559b"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/motazsaad/login-ds/master/datasets/IRIS.csv"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-13 10:49:59--  https://raw.githubusercontent.com/motazsaad/login-ds/master/datasets/IRIS.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4466 (4.4K) [text/plain]\n",
            "Saving to: ‘IRIS.csv.1’\n",
            "\n",
            "\rIRIS.csv.1            0%[                    ]       0  --.-KB/s               \rIRIS.csv.1          100%[===================>]   4.36K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-13 10:49:59 (62.3 MB/s) - ‘IRIS.csv.1’ saved [4466/4466]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQAM72IEudbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "311d82fe-c049-4dc0-a859-4a0808be8c34"
      },
      "source": [
        "df = pd.read_csv('IRIS.csv')\n",
        "df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width         species\n",
              "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
              "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
              "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
              "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
              "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
              "..            ...          ...           ...          ...             ...\n",
              "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
              "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
              "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
              "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
              "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lK33yjkuls_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "a1f3c2c4-381b-4d5d-e9fb-b9f8b6379513"
      },
      "source": [
        "df['species'] = pd.Categorical(df['species'])\n",
        "df['species'] = df.species.cat.codes\n",
        "df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width  species\n",
              "0             5.1          3.5           1.4          0.2        0\n",
              "1             4.9          3.0           1.4          0.2        0\n",
              "2             4.7          3.2           1.3          0.2        0\n",
              "3             4.6          3.1           1.5          0.2        0\n",
              "4             5.0          3.6           1.4          0.2        0\n",
              "..            ...          ...           ...          ...      ...\n",
              "145           6.7          3.0           5.2          2.3        2\n",
              "146           6.3          2.5           5.0          1.9        2\n",
              "147           6.5          3.0           5.2          2.0        2\n",
              "148           6.2          3.4           5.4          2.3        2\n",
              "149           5.9          3.0           5.1          1.8        2\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKgYixP0vc2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd07dcaf-41f2-44fb-f366-920cb77c66d8"
      },
      "source": [
        "val_df = df.sample(frac=0.2, random_state=1337)\n",
        "train_df = df.drop(val_df.index)\n",
        "\n",
        "print(\n",
        "    \"Using %d samples for training and %d for validation\"\n",
        "    % (len(train_df), len(val_df))\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 120 samples for training and 30 for validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9ulg2XPwM-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe, target, shuffle=True, batch_size=10):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop(target)\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXZ7YUquwXm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = df_to_dataset(dataframe=train_df, target='species')\n",
        "val_ds = df_to_dataset(dataframe=val_df,  target='species')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTnYauf-wzSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "818aab71-bfc5-4676-8168-e2eb72e89c89"
      },
      "source": [
        "from tensorflow import feature_column\n",
        "\n",
        "feature_columns = []\n",
        "# numeric cols\n",
        "for col in df.columns:\n",
        "  if col == 'species':\n",
        "    continue\n",
        "  feature_columns.append(feature_column.numeric_column(col, dtype=tf.float16)) \n",
        "feature_columns"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[NumericColumn(key='sepal_length', shape=(1,), default_value=None, dtype=tf.float16, normalizer_fn=None),\n",
              " NumericColumn(key='sepal_width', shape=(1,), default_value=None, dtype=tf.float16, normalizer_fn=None),\n",
              " NumericColumn(key='petal_length', shape=(1,), default_value=None, dtype=tf.float16, normalizer_fn=None),\n",
              " NumericColumn(key='petal_width', shape=(1,), default_value=None, dtype=tf.float16, normalizer_fn=None)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVFIezP1xeJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYmmT5Syxq_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f83dbed2-28c4-4fbf-ade2-251d80c806bc"
      },
      "source": [
        "df.species.unique()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXBPV3Lxxg4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.DenseFeatures(feature_columns))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-opca_cyllK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpfxh0uvyyDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "233a3a3f-132e-46ab-e059-f63e6647e361"
      },
      "source": [
        "model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=100)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.0024 - accuracy: 0.3917 - val_loss: 0.9530 - val_accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8488 - accuracy: 0.8333 - val_loss: 0.7382 - val_accuracy: 0.9000\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7596 - accuracy: 0.6417 - val_loss: 0.6190 - val_accuracy: 0.9000\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.8333 - val_loss: 0.5902 - val_accuracy: 0.9000\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.9000 - val_loss: 0.5056 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7500 - val_loss: 0.4597 - val_accuracy: 0.9667\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.9583 - val_loss: 0.4420 - val_accuracy: 0.9333\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.8667 - val_loss: 0.4024 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.9583 - val_loss: 0.3658 - val_accuracy: 0.9667\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.9583 - val_loss: 0.3691 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8833 - val_loss: 0.3474 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8167 - val_loss: 0.3185 - val_accuracy: 0.9667\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.9250 - val_loss: 0.3411 - val_accuracy: 0.9333\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.9667 - val_loss: 0.3074 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.9750 - val_loss: 0.2899 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.9500 - val_loss: 0.2889 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.9583 - val_loss: 0.2795 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.9667 - val_loss: 0.2812 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.9583 - val_loss: 0.2473 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.9250 - val_loss: 0.2613 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.9333 - val_loss: 0.2551 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.9583 - val_loss: 0.2285 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.9667 - val_loss: 0.2516 - val_accuracy: 0.9667\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.9583 - val_loss: 0.2047 - val_accuracy: 0.9667\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.9667 - val_loss: 0.2159 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2726 - accuracy: 0.9667 - val_loss: 0.2080 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.9667 - val_loss: 0.2261 - val_accuracy: 0.9667\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.9417 - val_loss: 0.1940 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.9833 - val_loss: 0.2010 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2415 - accuracy: 0.9667 - val_loss: 0.1917 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.9750 - val_loss: 0.1782 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9750 - val_loss: 0.2126 - val_accuracy: 0.9667\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9667 - val_loss: 0.1642 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2193 - accuracy: 0.9667 - val_loss: 0.1840 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9750 - val_loss: 0.1588 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9667 - val_loss: 0.1909 - val_accuracy: 0.9667\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9667 - val_loss: 0.1540 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9667 - val_loss: 0.1476 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9833 - val_loss: 0.1654 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1909 - accuracy: 0.9750 - val_loss: 0.1382 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1867 - accuracy: 0.9667 - val_loss: 0.1441 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9667 - val_loss: 0.1670 - val_accuracy: 0.9667\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9583 - val_loss: 0.1362 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.9583 - val_loss: 0.1317 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1709 - accuracy: 0.9750 - val_loss: 0.1314 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1659 - accuracy: 0.9667 - val_loss: 0.1288 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9750 - val_loss: 0.1323 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9667 - val_loss: 0.1163 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9750 - val_loss: 0.1229 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9500 - val_loss: 0.1206 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9750 - val_loss: 0.1194 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9750 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9750 - val_loss: 0.1179 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9667 - val_loss: 0.1276 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1531 - accuracy: 0.9583 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9667 - val_loss: 0.1015 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9667 - val_loss: 0.1150 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9750 - val_loss: 0.0974 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9667 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9667 - val_loss: 0.0997 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1311 - accuracy: 0.9667 - val_loss: 0.1058 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1344 - accuracy: 0.9583 - val_loss: 0.0906 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9583 - val_loss: 0.1027 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9750 - val_loss: 0.0964 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9750 - val_loss: 0.0863 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9750 - val_loss: 0.0910 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1234 - accuracy: 0.9750 - val_loss: 0.1038 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9750 - val_loss: 0.0838 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9583 - val_loss: 0.0959 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9667 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.9750 - val_loss: 0.0930 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9667 - val_loss: 0.0819 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9833 - val_loss: 0.0906 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9750 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9583 - val_loss: 0.0862 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.9667 - val_loss: 0.0892 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9500 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 0.9667 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9667 - val_loss: 0.0889 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9667 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9750 - val_loss: 0.0853 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9750 - val_loss: 0.0672 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9583 - val_loss: 0.0884 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9583 - val_loss: 0.0631 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9667 - val_loss: 0.0857 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9667 - val_loss: 0.0633 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9750 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9750 - val_loss: 0.0721 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1005 - accuracy: 0.9667 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9750 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9667 - val_loss: 0.0722 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.9750 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9667 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9667 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0937 - accuracy: 0.9750 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9750 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.9667 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9750 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9750 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9667 - val_loss: 0.0591 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f799d38cb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wTCyIksy3e1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1fa2ea6d-8897-4803-cd25-6465520d0154"
      },
      "source": [
        "model.evaluate(val_ds)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05905679240822792, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LRHzPDczfcm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "bfb1a64a-6d92-4caf-9b0b-9d0ff01a9f55"
      },
      "source": [
        "model.predict(val_ds)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.98658657e-01, 1.34129089e-03, 3.94355881e-09],\n",
              "       [3.06657384e-05, 4.65277061e-02, 9.53441620e-01],\n",
              "       [3.22767012e-02, 9.63478446e-01, 4.24478855e-03],\n",
              "       [1.76658004e-03, 9.63027418e-01, 3.52060162e-02],\n",
              "       [3.69456611e-05, 1.24368131e-01, 8.75594914e-01],\n",
              "       [7.40031919e-06, 2.48699486e-02, 9.75122690e-01],\n",
              "       [3.19314694e-07, 4.54065250e-03, 9.95459080e-01],\n",
              "       [1.14992568e-02, 9.86340523e-01, 2.16015172e-03],\n",
              "       [9.99715149e-01, 2.84805341e-04, 2.19858728e-10],\n",
              "       [1.42008475e-05, 3.26893926e-01, 6.73091888e-01],\n",
              "       [9.96614516e-01, 3.38551728e-03, 1.32007543e-08],\n",
              "       [9.98178482e-01, 1.82155950e-03, 4.75721951e-09],\n",
              "       [9.93197799e-01, 6.80219149e-03, 3.88041670e-08],\n",
              "       [9.98069704e-01, 1.93037314e-03, 1.03976978e-08],\n",
              "       [9.99843001e-01, 1.56942697e-04, 4.85034408e-11],\n",
              "       [9.99179661e-01, 8.20316607e-04, 1.81218740e-09],\n",
              "       [5.30917669e-06, 4.58075739e-02, 9.54187095e-01],\n",
              "       [9.95593131e-01, 4.40683588e-03, 3.14586295e-08],\n",
              "       [6.14524542e-05, 2.40715399e-01, 7.59223163e-01],\n",
              "       [9.98253167e-01, 1.74676522e-03, 1.47312891e-08],\n",
              "       [4.69573223e-07, 6.66047679e-03, 9.93339002e-01],\n",
              "       [9.98720586e-01, 1.27937272e-03, 3.59322350e-09],\n",
              "       [1.32743386e-03, 8.63765836e-01, 1.34906679e-01],\n",
              "       [8.10425496e-04, 7.61121094e-01, 2.38068491e-01],\n",
              "       [9.98765111e-01, 1.23493443e-03, 4.05358058e-09],\n",
              "       [1.56028102e-06, 4.43903022e-02, 9.55608130e-01],\n",
              "       [9.93301630e-01, 6.69842679e-03, 4.53588633e-08],\n",
              "       [1.23303425e-05, 1.83861062e-01, 8.16126585e-01],\n",
              "       [1.32212676e-06, 4.15152386e-02, 9.58483458e-01],\n",
              "       [9.94518459e-01, 5.48148854e-03, 3.73757736e-08]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    }
  ]
}