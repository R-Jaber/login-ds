{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8NeYLe4t4mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBy_Qo7Yt_kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d6dc0843-93ca-4959-9384-daaa90cf368c"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/motazsaad/login-ds/master/datasets/IRIS.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-15 05:21:12--  https://raw.githubusercontent.com/motazsaad/login-ds/master/datasets/IRIS.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4466 (4.4K) [text/plain]\n",
            "Saving to: ‘IRIS.csv.1’\n",
            "\n",
            "\rIRIS.csv.1            0%[                    ]       0  --.-KB/s               \rIRIS.csv.1          100%[===================>]   4.36K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-15 05:21:13 (38.6 MB/s) - ‘IRIS.csv.1’ saved [4466/4466]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQAM72IEudbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "92a0e053-d46d-40c5-e4eb-6c544aea4bb5"
      },
      "source": [
        "df = pd.read_csv('IRIS.csv')\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width         species\n",
              "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
              "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
              "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
              "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
              "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
              "..            ...          ...           ...          ...             ...\n",
              "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
              "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
              "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
              "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
              "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lK33yjkuls_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "a157643c-3931-4702-8e5f-6140f064cb1f"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "df['species'] = encoder.fit_transform((df['species']))\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width  species\n",
              "0             5.1          3.5           1.4          0.2        0\n",
              "1             4.9          3.0           1.4          0.2        0\n",
              "2             4.7          3.2           1.3          0.2        0\n",
              "3             4.6          3.1           1.5          0.2        0\n",
              "4             5.0          3.6           1.4          0.2        0\n",
              "..            ...          ...           ...          ...      ...\n",
              "145           6.7          3.0           5.2          2.3        2\n",
              "146           6.3          2.5           5.0          1.9        2\n",
              "147           6.5          3.0           5.2          2.0        2\n",
              "148           6.2          3.4           5.4          2.3        2\n",
              "149           5.9          3.0           5.1          1.8        2\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKgYixP0vc2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73117c6a-7d22-4b5b-8476-5f8fd6a792ca"
      },
      "source": [
        "val_df = df.sample(frac=0.2, random_state=1337)\n",
        "train_df = df.drop(val_df.index)\n",
        "\n",
        "print(\n",
        "    \"Using %d samples for training and %d for validation\"\n",
        "    % (len(train_df), len(val_df))\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 120 samples for training and 30 for validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9ulg2XPwM-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe, target, shuffle=True, batch_size=10):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop(target)\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXZ7YUquwXm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = df_to_dataset(dataframe=train_df, target='species')\n",
        "val_ds = df_to_dataset(dataframe=val_df,  target='species')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2djq5NXn2gvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "87d6c05f-4422-4e12-ae18-d2245d49c87d"
      },
      "source": [
        "for r in train_ds.take(1):\n",
        "  print(r)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'sepal_length': <tf.Tensor: shape=(10,), dtype=float64, numpy=array([5.7, 6.1, 6.4, 5.5, 6.1, 7.7, 4.4, 6.7, 5.2, 6.8])>, 'sepal_width': <tf.Tensor: shape=(10,), dtype=float64, numpy=array([4.4, 3. , 2.9, 2.4, 2.8, 3.8, 2.9, 3. , 3.4, 3.2])>, 'petal_length': <tf.Tensor: shape=(10,), dtype=float64, numpy=array([1.5, 4.6, 4.3, 3.8, 4. , 6.7, 1.4, 5. , 1.4, 5.9])>, 'petal_width': <tf.Tensor: shape=(10,), dtype=float64, numpy=array([0.4, 1.4, 1.3, 1.1, 1.3, 2.2, 0.2, 1.7, 0.2, 2.3])>}, <tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 1, 1, 1, 1, 2, 0, 1, 0, 2])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTnYauf-wzSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "551e20df-4741-4f96-a714-79793585af29"
      },
      "source": [
        "from tensorflow import feature_column\n",
        "\n",
        "feature_columns = []\n",
        "# numeric cols\n",
        "for col in df.columns:\n",
        "  if col == 'species':\n",
        "    continue\n",
        "  feature_columns.append(feature_column.numeric_column(col, dtype=tf.float16)) \n",
        "feature_columns"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[NumericColumn(key='sepal_length', shape=(1,), default_value=None, dtype=tf.float16, normalizer_fn=None),\n",
              " NumericColumn(key='sepal_width', shape=(1,), default_value=None, dtype=tf.float16, normalizer_fn=None),\n",
              " NumericColumn(key='petal_length', shape=(1,), default_value=None, dtype=tf.float16, normalizer_fn=None),\n",
              " NumericColumn(key='petal_width', shape=(1,), default_value=None, dtype=tf.float16, normalizer_fn=None)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVFIezP1xeJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYmmT5Syxq_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01c7244b-30a0-4064-e487-b58db814e58c"
      },
      "source": [
        "df.species.unique()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXBPV3Lxxg4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.DenseFeatures(feature_columns))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-opca_cyllK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpfxh0uvyyDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bfdc9be9-b31d-4518-8d94-cd95c4d8fd12"
      },
      "source": [
        "model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=100)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9962 - accuracy: 0.4250 - val_loss: 0.9810 - val_accuracy: 0.1667\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8749 - accuracy: 0.7583 - val_loss: 0.8110 - val_accuracy: 0.9333\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7896 - accuracy: 0.7583 - val_loss: 0.6843 - val_accuracy: 0.9000\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7169 - accuracy: 0.8333 - val_loss: 0.6653 - val_accuracy: 0.9000\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.7833 - val_loss: 0.5800 - val_accuracy: 0.9667\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6750 - val_loss: 0.4950 - val_accuracy: 0.9000\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.8250 - val_loss: 0.5200 - val_accuracy: 0.8667\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.9083 - val_loss: 0.4663 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.9667 - val_loss: 0.4191 - val_accuracy: 0.9667\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.9083 - val_loss: 0.4032 - val_accuracy: 0.9667\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.9083 - val_loss: 0.4216 - val_accuracy: 0.9000\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.9167 - val_loss: 0.3461 - val_accuracy: 0.9667\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.9167 - val_loss: 0.3612 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.9417 - val_loss: 0.3611 - val_accuracy: 0.9667\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.9667 - val_loss: 0.3248 - val_accuracy: 0.9667\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.9250 - val_loss: 0.3238 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.9583 - val_loss: 0.3078 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.9500 - val_loss: 0.2957 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.9417 - val_loss: 0.3012 - val_accuracy: 0.9667\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.9667 - val_loss: 0.2671 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.9417 - val_loss: 0.2731 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.9667 - val_loss: 0.2565 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.9583 - val_loss: 0.2440 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.9667 - val_loss: 0.2609 - val_accuracy: 0.9667\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.9500 - val_loss: 0.2517 - val_accuracy: 0.9667\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.9417 - val_loss: 0.2171 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.9750 - val_loss: 0.2381 - val_accuracy: 0.9667\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.9667 - val_loss: 0.2187 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.9500 - val_loss: 0.2064 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.9583 - val_loss: 0.2280 - val_accuracy: 0.9667\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9750 - val_loss: 0.1887 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9667 - val_loss: 0.2115 - val_accuracy: 0.9667\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.9417 - val_loss: 0.1980 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9583 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9500 - val_loss: 0.2028 - val_accuracy: 0.9667\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9667 - val_loss: 0.1600 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9667 - val_loss: 0.1842 - val_accuracy: 0.9667\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9667 - val_loss: 0.1603 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9583 - val_loss: 0.1572 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9667 - val_loss: 0.1659 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9667 - val_loss: 0.1562 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9667 - val_loss: 0.1592 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9667 - val_loss: 0.1456 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9667 - val_loss: 0.1578 - val_accuracy: 0.9667\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9583 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9667 - val_loss: 0.1564 - val_accuracy: 0.9667\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9667 - val_loss: 0.1274 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.9750 - val_loss: 0.1338 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1601 - accuracy: 0.9750 - val_loss: 0.1404 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.9667 - val_loss: 0.1224 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9667 - val_loss: 0.1229 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9583 - val_loss: 0.1307 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9750 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9417 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9750 - val_loss: 0.1359 - val_accuracy: 0.9667\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1498 - accuracy: 0.9583 - val_loss: 0.1199 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9583 - val_loss: 0.1121 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9417 - val_loss: 0.1202 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9667 - val_loss: 0.0972 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.9750 - val_loss: 0.1217 - val_accuracy: 0.9667\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9667 - val_loss: 0.1143 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9667 - val_loss: 0.0943 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9750 - val_loss: 0.1072 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9667 - val_loss: 0.1036 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9667 - val_loss: 0.1007 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9583 - val_loss: 0.1048 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9750 - val_loss: 0.1059 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9667 - val_loss: 0.0873 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1176 - accuracy: 0.9583 - val_loss: 0.1006 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9583 - val_loss: 0.0917 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9667 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9500 - val_loss: 0.1017 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9833 - val_loss: 0.0784 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9667 - val_loss: 0.0973 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9583 - val_loss: 0.0793 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1205 - accuracy: 0.9667 - val_loss: 0.0940 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9667 - val_loss: 0.0868 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9750 - val_loss: 0.0907 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9667 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.9667 - val_loss: 0.0948 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9750 - val_loss: 0.0954 - val_accuracy: 0.9667\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9667 - val_loss: 0.0698 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9750 - val_loss: 0.0915 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9750 - val_loss: 0.0832 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9667 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9583 - val_loss: 0.0927 - val_accuracy: 0.9667\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.9667 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9750 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9667 - val_loss: 0.0866 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9750 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9667 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9667 - val_loss: 0.0726 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9750 - val_loss: 0.0582 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9750 - val_loss: 0.0957 - val_accuracy: 0.9667\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9750 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.9667 - val_loss: 0.0672 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9583 - val_loss: 0.0624 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9583 - val_loss: 0.0709 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9667 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9667 - val_loss: 0.0636 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc6c66cba20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwU-07q368SA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "3570bf75-5def-422f-ef85-e10a29d0136a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_features (DenseFeature multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  640       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  387       \n",
            "=================================================================\n",
            "Total params: 1,027\n",
            "Trainable params: 1,027\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wTCyIksy3e1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b1301a62-c4e0-4dc0-c6b9-2002510086ed"
      },
      "source": [
        "model.evaluate(val_ds)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06360798329114914, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LRHzPDczfcm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "f32a4243-662b-4f4e-b7bc-301c2755437e"
      },
      "source": [
        "model.predict(val_ds)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9715281e-01, 2.8471588e-03, 2.4888644e-09],\n",
              "       [9.9698132e-01, 3.0186640e-03, 5.2312932e-09],\n",
              "       [9.9755609e-01, 2.4438354e-03, 2.4593334e-09],\n",
              "       [9.9807906e-01, 1.9209252e-03, 1.8642432e-09],\n",
              "       [5.2107644e-05, 4.4316139e-02, 9.5563173e-01],\n",
              "       [2.1231035e-06, 4.3730583e-02, 9.5626730e-01],\n",
              "       [1.5314244e-03, 7.6961470e-01, 2.2885391e-01],\n",
              "       [9.9139321e-01, 8.6068166e-03, 2.6242821e-08],\n",
              "       [1.9673580e-02, 9.7765428e-01, 2.6721235e-03],\n",
              "       [5.5095359e-07, 4.7032330e-03, 9.9529618e-01],\n",
              "       [1.8480875e-03, 8.5298461e-01, 1.4516731e-01],\n",
              "       [2.1666136e-05, 1.9527300e-01, 8.0470532e-01],\n",
              "       [9.9056810e-01, 9.4319684e-03, 2.7226736e-08],\n",
              "       [1.3034103e-05, 2.4417467e-02, 9.7556949e-01],\n",
              "       [9.9256754e-01, 7.4324594e-03, 2.0910381e-08],\n",
              "       [4.4613462e-02, 9.5066410e-01, 4.7223964e-03],\n",
              "       [2.0033399e-06, 4.2332295e-02, 9.5766574e-01],\n",
              "       [9.9833703e-01, 1.6628836e-03, 9.1767965e-10],\n",
              "       [7.0556125e-05, 1.2842155e-01, 8.7150794e-01],\n",
              "       [8.0572710e-07, 6.6942754e-03, 9.9330491e-01],\n",
              "       [3.0415799e-03, 9.6299976e-01, 3.3958711e-02],\n",
              "       [9.8770428e-01, 1.2295689e-02, 3.3247545e-08],\n",
              "       [9.9719006e-01, 2.8099502e-03, 6.7579498e-09],\n",
              "       [9.2909258e-06, 4.6785329e-02, 9.5320541e-01],\n",
              "       [9.9970776e-01, 2.9224058e-04, 1.7392652e-11],\n",
              "       [1.1270174e-04, 2.4954404e-01, 7.5034326e-01],\n",
              "       [9.9786276e-01, 2.1372410e-03, 1.8835917e-09],\n",
              "       [9.9528414e-01, 4.7158347e-03, 7.1120372e-09],\n",
              "       [9.9933547e-01, 6.6453533e-04, 8.2013174e-11],\n",
              "       [2.9609231e-05, 3.6646309e-01, 6.3350731e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY8tH7l_0Et6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00370b98-981a-4440-b775-705efdb3ed30"
      },
      "source": [
        "print(np.argmax(model.predict(val_ds), axis=1).tolist())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 0, 2, 2, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 2, 2, 1, 1, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwEl2jLx0V6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "aee3e568-f13c-4bbb-9ce9-c3c7a60a705d"
      },
      "source": [
        "new_data = {\n",
        "    'sepal_length': [5.0],\n",
        "    'sepal_width': [1.2], \n",
        "    'petal_length': [3.5],\n",
        "    'petal_width': [0.7]\n",
        "}\n",
        "\n",
        "new_data2 = {\n",
        "    'sepal_length': [5.0, 5.1],\n",
        "    'sepal_width': [1.2, 1.3], \n",
        "    'petal_length': [3.5, 3.4],\n",
        "    'petal_width': [0.7, 0.4]\n",
        "}\n",
        "\n",
        "new_df = pd.DataFrame(data=new_data)\n",
        "new_df"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width\n",
              "0           5.0          1.2           3.5          0.7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UADhQMCQ2HwX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e10dc010-5d54-479d-edeb-786eb1595469"
      },
      "source": [
        "input_dict = {name: tf.convert_to_tensor([value]) for name, value in new_df.items()}\n",
        "input_dict"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'petal_length': <tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[3.5]])>,\n",
              " 'petal_width': <tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[0.7]])>,\n",
              " 'sepal_length': <tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[5.]])>,\n",
              " 'sepal_width': <tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[1.2]])>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqPeNfx30q4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f075df4-8b47-4284-af59-2f170b493a07"
      },
      "source": [
        "model.predict(input_dict)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00237346, 0.9220018 , 0.07562487]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNk6tm_J7IxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b73b4f3e-7d34-46bb-86bf-7958954dd930"
      },
      "source": [
        "print(np.argmax(model.predict(input_dict), axis=1).tolist())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}